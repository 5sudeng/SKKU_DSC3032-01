{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1phOsObqDlmGHyHXDYybGsXIpRkEuR5is","timestamp":1679067122818},{"file_id":"1b-j4EHyzMtzndpaNo1UmLqKg5xkyYvS2","timestamp":1678873016748},{"file_id":"1iwlntnn-heodPChz5jtVWC_5DMDD8-E2","timestamp":1646796400081}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"42CRdtcCRTuc"},"source":["# Assignment 1 – Polynomial Regression using ``torch.nn.Module``\n","\n","- Please create a copy of this notebook onto your own Drive before working on it: `File-->Save a copy in Drive`\n","- Please submit your ipynb file named with your initials, e.g. `KJH-Assignment1.ipynb` (or a URL link to it) with **the CODE cells output visible** to support your answers and **TEXTUAL answers given as comments** in the code cells.\n","- Marks will be deducted for missing or partial code cell output where applicable.\n","- Deadline for submission is **9:00am, Saturday, March 25th.**"]},{"cell_type":"markdown","metadata":{"id":"0KvsIo2UfwO3"},"source":["## Neural Network Model for Polynomial Regression\n","Your task is to build **TWO different neural network models** for the function $y = x^2 + 5x$\n","\n","Requirements:\n","- You MUST use `torch.nn.Module` to define your neural network classes.\n","- A random seed is provided to help with code reproducibility so the code will always produce the same result each time you run it.\n","- The training data should have **10 input values, $x$, and the correct corresponding output values, $y$,** for the function $y = x^2 + 5x$ \n","- Each NN may have **maximum TWO hidden layers**.\n","- You may use a **maximum of 500 neuron units in each hidden layer**.\n","- You may train over a **maximum of 1000 epochs**.\n","- Use suitable activation functions that have been covered in class. \n","  - Note: Activation function should be used in every layer and the output layer depending on the type of output.\n","- You MUST use the **Adam optimiser,** available as **`torch.optim.Adam()`** and the **mean squared error (MSE) loss function**.\n","- **IMPORTANT:** **Your best 2 models should have a loss lower than 0.01** at the end of training.\n","- If the loss value is the same, you can fill it out regardless of the rank.\n","- Please write down **the top 2 models** with the best performance in terms of **lowest loss** from your experiment, including **the number of layers, hidden sizes, learning rate, epochs, and the final loss after running all epochs.**\n","- Print the loss at every 50th epoch. \n","- Test the model on $x=10$.\n","- **Save your training loss** at every iteration.\n","\n","Note:\n","- If your model does not achieve a loss of less than 0.01, you will still be awarded marks for `Q7 – Q10` as long as you can explain your answers accordingly.\n","- For `Q7 – Q12`, please respond with the cases where the loss is the lowest."]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# 1. Define training data for a the mathematical formula y = x^2 + 5x (3)\n","x = torch.tensor([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]], dtype = torch.float32)\n","y = torch.tensor([[6],[14],[24],[36],[50],[66],[84],[104],[126],[150]], dtype = torch.float32)"],"metadata":{"id":"ek4MzzzQYbdp","executionInfo":{"status":"ok","timestamp":1679590885837,"user_tz":-540,"elapsed":308,"user":{"displayName":"오수정","userId":"02461527994138035193"}}},"execution_count":70,"outputs":[]},{"cell_type":"markdown","source":["# top 1"],"metadata":{"id":"PBAcuKIEU8_w"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679590887548,"user_tz":-540,"elapsed":962,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"ebc696f6-835e-4901-a101-b41d89697d89","id":"fqZfb3eg9q8_"},"source":["# Top 1 Accuracy Model (the model that has the lowest loss)\n","torch.manual_seed(40) # This is for reproducibility. You need NOT adjust this.\n","\n","# 2. Define NN class 1 (10)\n","class sNN(nn.Module) :\n","  def __init__(self, hidden_size) :\n","    super().__init__()\n","    self.linear1 = nn.Linear(1, hidden_size)\n","    self.activation = nn.LeakyReLU()\n","    self.linear2 = nn.Linear(hidden_size, int(hidden_size*0.6))\n","    self.linear3 = nn.Linear(int(hidden_size*0.6), 1)\n","\n","  def forward(self, x) :\n","    out = self.linear1(x)\n","    out = self.activation(out)\n","    out = self.linear2(out)\n","    out = self.activation(out)\n","    out = self.linear3(out)\n","    return out\n","\n","# 3. Create an instance of NN model and define the hidden_size (2)\n","hidden_size = 500\n","model = sNN(hidden_size)\n","\n","# 4. Loss and Optimiser (2)\n","learning_rate = 0.01\n","loss_fn = nn.MSELoss()\n","opt = torch.optim.Adam(model.parameters(), lr = learning_rate)\n","\n","# 5. Training loop\n","num_epochs = 800\n","losses1 = []\n","for epoch in range(num_epochs):\n","  # 5.1 Forward pass (2)\n","  y_pred = model(x)\n","  loss = loss_fn(y_pred, y)\n","\n","  # 5.2 Backward pass (3)\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","\n","  # 5.3 Print loss every 50th epoch (1)\n","  if (epoch + 1) % 50 == 0 :\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss={loss.item():.6f}')\n","  # 5.4 Save training loss at every epoch (2)\n","  losses1.append(loss.item())"],"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 50/800, Loss=16.270557\n","Epoch 100/800, Loss=1.116403\n","Epoch 150/800, Loss=0.226010\n","Epoch 200/800, Loss=0.080125\n","Epoch 250/800, Loss=0.045309\n","Epoch 300/800, Loss=0.023855\n","Epoch 350/800, Loss=0.015307\n","Epoch 400/800, Loss=0.005134\n","Epoch 450/800, Loss=0.001993\n","Epoch 500/800, Loss=0.060794\n","Epoch 550/800, Loss=0.002127\n","Epoch 600/800, Loss=0.000375\n","Epoch 650/800, Loss=0.000103\n","Epoch 700/800, Loss=0.000026\n","Epoch 750/800, Loss=0.000006\n","Epoch 800/800, Loss=0.000001\n"]}]},{"cell_type":"markdown","source":["# Top 2"],"metadata":{"id":"G6VDcsPQU-8g"}},{"cell_type":"code","source":["# Top 2 Accuracy Model (the model that has the second lowest loss)\n","torch.manual_seed(40) # This is for reproducibility. You need NOT adjust this.\n","\n","# 2. Define NN class 2\n","class sNN(nn.Module) :\n","  def __init__(self, hidden_size) :\n","    super().__init__()\n","    self.linear1 = nn.Linear(1, hidden_size)\n","    self.activation = nn.ReLU()\n","    self.linear2 = nn.Linear(hidden_size, hidden_size)\n","    self.linear3 = nn.Linear(hidden_size, 1)\n","\n","\n","  def forward(self, x) :\n","    out = self.linear1(x)\n","    out = self.activation(out)\n","    out = self.linear2(out)\n","    out = self.activation(out)\n","    out = self.linear3(out)\n","    return out\n","\n","# 3. Create an instance of NN model and define the hidden_size \n","hidden_size = 500\n","model2 = sNN(hidden_size)\n","\n","# 4. Loss and Optimiser \n","learning_rate = 0.01\n","loss_fn = nn.MSELoss()\n","opt = torch.optim.Adam(model2.parameters(), lr = learning_rate)\n","\n","# 5. Training loop\n","num_epochs = 650\n","losses2 = []\n","for epoch in range(num_epochs):\n","  # 5.1 Forward pass \n","  y_pred = model2(x)\n","  loss = loss_fn(y_pred, y)\n","\n","  # 5.2 Backward pass\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","\n","  # 5.3 Print loss every 50th epoch\n","  if  (epoch + 1) % 50 == 0 : \n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss={loss.item():.6f}')\n","  # 5.4 Save training loss at every epoch \n","  losses2.append(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPF6tLBg4NPJ","executionInfo":{"status":"ok","timestamp":1679590890054,"user_tz":-540,"elapsed":2508,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"69f7c5cb-e9d9-414d-9dea-c837422efcc8"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 50/650, Loss=30.886368\n","Epoch 100/650, Loss=1.656727\n","Epoch 150/650, Loss=0.222815\n","Epoch 200/650, Loss=0.076058\n","Epoch 250/650, Loss=0.040642\n","Epoch 300/650, Loss=0.025861\n","Epoch 350/650, Loss=0.011869\n","Epoch 400/650, Loss=0.003619\n","Epoch 450/650, Loss=0.001267\n","Epoch 500/650, Loss=0.000421\n","Epoch 550/650, Loss=0.000125\n","Epoch 600/650, Loss=0.000035\n","Epoch 650/650, Loss=0.000019\n"]}]},{"cell_type":"code","source":["# Q6. Please write down the top 2 models with the best performance in terms of lowest loss from your experiment. (3)\n","# Including the number of layers, hidden sizes, learning rate, epochs, and the final loss after running all epochs.\n","# Top 1\n","# number of layers: 1 input layer, 2 hidden layer, and 1 output layer\n","# number of hidden sizes: 500 (first hidden layer) / 300 (second hidden layer)\n","# learning rate: 0.01\n","# epochs: 800\n","# final loss: 0.000001\n","# activation func: LeakyReLU\n","\n","# Top 2:\n","# number of layers:  1 input layer, 2 hidden layer, and 1 output layer\n","# number of hidden sizes: 500\n","# learning rate: 0.01\n","# epochs: 650\n","# final loss: 0.000019\n","# activation func: ReLU\n"],"metadata":{"id":"dpVsWM1gKARA","executionInfo":{"status":"ok","timestamp":1679590890054,"user_tz":-540,"elapsed":19,"user":{"displayName":"오수정","userId":"02461527994138035193"}}},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":["For Q7-Q12, please respond using the best model (the model with the lowest loss)."],"metadata":{"id":"JRDul8uFKEOp"}},{"cell_type":"code","source":["# Q7. Visualize (3)\n","# Plot the landscape of your training loss (MSE loss) saved for every epoch.\n","# y-axis would mean MSE loss and x-axis would mean the epoch of your training.\n","# Hint: you should plot (1,first MSE loss), ... ,(last epoch number,last MSE loss)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","w_range = np.linspace(1, 800, 800)\n","plt.title(\"MSE Loss Plot\")\n","plt.plot(w_range,losses1)\n","plt.xlabel('Epoch')\n","plt.ylabel('MSE Loss')\n","plt.show()"],"metadata":{"id":"xXWhlxrmLBSl","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1679590890055,"user_tz":-540,"elapsed":19,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"b3e6a006-f23a-47ef-ecbd-cb2bf6ee21e5"},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"zatxfhYejeB8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679590890055,"user_tz":-540,"elapsed":17,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"e44beafb-03bd-4d99-a916-8785f938244b"},"source":["# Q8. Prediction (2)\n","# Let's use the model on a new number x, defined as a tensor\n","test_num = 10\n","test = torch.tensor([test_num], dtype=torch.float32)\n","# Get the model's prediction for this new x\n","print(f'Predicted value : {model(test).item():.4f}')"],"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted value : 149.9976\n"]}]},{"cell_type":"code","metadata":{"id":"RvmHgY1oDLiB","executionInfo":{"status":"ok","timestamp":1679590890057,"user_tz":-540,"elapsed":16,"user":{"displayName":"오수정","userId":"02461527994138035193"}}},"source":["# Make sure the output of your code cells support your answers below:\n","\n","# Q9. Describe how the loss changed over time during training. (2)\n","# Loss value decreased dramatically at first, but became decreased slower and slower, and \bsometimes it increases again. \n","\n","# Q10. Is the prediction for x=10 close enough to the ideal value of 150? \n","# Why do you think the prediction is or isn't close enough to the ideal value? (2)\n","# Model showed prediction '149.9976' and it's quite similar with 150. It's similar because it trained with number input between 1~10\n","# and correct label output. It trained quite well that data, so prediction is close enough 150.\n","\n","# Q11. What are the predictions for x=20 and x=100? Based on these predictions, \n","# comment on whether the model has captured the relationship between the training inputs and outputs. (2)\n","# Prediction for x=20 was 381.4797 while expecting 500, and prediction for x=100 was 2095.8186 while expecting 10500.\n","# As input value x goes far from trained value 1~10, differences between prediction value and actual value become bigger and bigger.\n","\n","# Q12. Apart from tweaking the number of epochs and the number of neuron units in the hidden layer, think\n","# of AT LEAST ONE more thing you would do to try to improve the model. You do NOT have to follow the \n","# requirements nor to implement anything. (1)\n","# 1. Increase size of Training Data\n","# 2. use train/test data set similar with real data (that we want to predict)"],"execution_count":76,"outputs":[]},{"cell_type":"code","source":["test_num = 20\n","test = torch.tensor([test_num], dtype=torch.float32)\n","# Get the model's prediction for this new x\n","print(f'Predicted value : {model(test).item():.4f}') #500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bB-6KQli5dau","executionInfo":{"status":"ok","timestamp":1679590890057,"user_tz":-540,"elapsed":16,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"a9208209-8d23-4795-8d87-0290526a59fe"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted value : 381.4797\n"]}]},{"cell_type":"code","source":["test_num = 100\n","test = torch.tensor([test_num], dtype=torch.float32)\n","# Get the model's prediction for this new x\n","print(f'Predicted value : {model(test).item():.4f}') #10500"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qx2xGh_iCjC2","executionInfo":{"status":"ok","timestamp":1679590890058,"user_tz":-540,"elapsed":15,"user":{"displayName":"오수정","userId":"02461527994138035193"}},"outputId":"3ae7b206-8bb6-406a-f483-75c9199b5b3f"},"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted value : 2095.8186\n"]}]}]}